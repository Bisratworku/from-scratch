{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dcedd979",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scratch import *\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "09164a03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'datasets\\\\fashion_mnist_images'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folder = \"datasets\\\\fashion_mnist_images\"\n",
    "folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "329cca94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label = os.listdir(os.path.join(folder, \"train\"))\n",
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "efe88256",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0000.png'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shirt = os.listdir(os.path.join(folder, \"train\", \"0\"))\n",
    "shirt[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f1db0d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(path:str, dataset:str):\n",
    "    label = os.listdir(os.path.join(path, dataset))\n",
    "    X = []\n",
    "    y = []\n",
    "    for lbl in label:\n",
    "        for file in os.listdir(os.path.join(path, dataset, lbl)):\n",
    "             try:  \n",
    "                image = np.array(Image.open(os.path.join(path,dataset, lbl, file)))\n",
    "                X.append(image/255)\n",
    "                y.append(lbl)\n",
    "             except:\n",
    "                continue\n",
    "    return np.array(X), np.array(y).astype(\"uint8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5ce14b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(path:str):\n",
    "    X_train, y_train = prepare_dataset(path, \"train\")\n",
    "    X_test, y_test = prepare_dataset(path, \"test\")\n",
    "    return X_train.reshape(-1, 28*28), y_train, X_test.reshape(-1, 28 *28), y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ef07fc06",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = create_dataset(folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6f4f4d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_batch(image, label, batch):\n",
    "    key = np.array(range(image.shape[0]))\n",
    "    np.random.shuffle(key)\n",
    "    image = image[key]\n",
    "    label = label[key]\n",
    "    img_split = np.array_split(image, batch)\n",
    "    lbl_split = np.array_split(label, batch)\n",
    "    return img_split, lbl_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc0ce0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch_image , train_batch_label = shuffle_batch(X_train, y_train, 120)\n",
    "test_batch_image, test_batch_label = shuffle_batch(X_test, y_test, 120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "66c2c679",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = np.random.randn(100, 2)\n",
    "j = np.random.randint(0,1, 100)\n",
    "l = np.random.randn(50,2)\n",
    "k = np.random.randint(0,1,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dcd90c53",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (59969,10) (500,10) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 12\u001b[0m\n\u001b[0;32m     10\u001b[0m m\u001b[38;5;241m.\u001b[39madd(Activation_Softmax())\n\u001b[0;32m     11\u001b[0m m\u001b[38;5;241m.\u001b[39mset(    loss \u001b[38;5;241m=\u001b[39m Loss_CategoricalCrossentropy(),optimizer \u001b[38;5;241m=\u001b[39m Optimizer_Adam(decay \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1e-4\u001b[39m))\n\u001b[1;32m---> 12\u001b[0m m\u001b[38;5;241m.\u001b[39mtrain( X_train, y_train,epoches\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m, batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m120\u001b[39m)\n",
      "File \u001b[1;32m~\\OneDrive\\Documents\\GitHub\\from-scratch\\scratch.py:324\u001b[0m, in \u001b[0;36mmodel.train\u001b[1;34m(self, X, y, epoches, print_every, batch)\u001b[0m\n\u001b[0;32m    322\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m,  epoches \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m    323\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward(data[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpasses], label[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpasses])\n\u001b[1;32m--> 324\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackward(y)\n\u001b[0;32m    325\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimaizer\u001b[38;5;241m.\u001b[39mpre_update_params()\n\u001b[0;32m    326\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m tunable_layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtunable_layers:\n",
      "File \u001b[1;32m~\\OneDrive\\Documents\\GitHub\\from-scratch\\scratch.py:307\u001b[0m, in \u001b[0;36mmodel.backward\u001b[1;34m(self, label)\u001b[0m\n\u001b[0;32m    306\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbackward\u001b[39m(\u001b[38;5;28mself\u001b[39m,label):\n\u001b[1;32m--> 307\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss\u001b[38;5;241m.\u001b[39mbackward(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlast_layer_output, label)\n\u001b[0;32m    308\u001b[0m     dinputs \u001b[38;5;241m=\u001b[39m  \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss\u001b[38;5;241m.\u001b[39mdinputs\n\u001b[0;32m    309\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mreversed\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers):\n",
      "File \u001b[1;32m~\\OneDrive\\Documents\\GitHub\\from-scratch\\scratch.py:219\u001b[0m, in \u001b[0;36mLoss_CategoricalCrossentropy.backward\u001b[1;34m(self, dvalues, y_true)\u001b[0m\n\u001b[0;32m    217\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(y_true\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    218\u001b[0m     y_true \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39meye(labels)[y_true]\n\u001b[1;32m--> 219\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdinputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39my_true \u001b[38;5;241m/\u001b[39m dvalues\n\u001b[0;32m    220\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdinputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdinputs \u001b[38;5;241m/\u001b[39m samples\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (59969,10) (500,10) "
     ]
    }
   ],
   "source": [
    "m = model()\n",
    "m.add(Layer_Dense(28*28,120, weight_regularizer_l2 = 0.001, bias_regularizer_l2 = 0.001))\n",
    "m.add(Activation_ReLU())\n",
    "m.add(Layer_Dropout(0.2))\n",
    "m.add(Layer_Dense(120,120, weight_regularizer_l2 = 0.001, bias_regularizer_l2 = 0.001))\n",
    "m.add(Activation_ReLU())\n",
    "m.add(Layer_Dense(120,120))\n",
    "m.add(Activation_ReLU())\n",
    "m.add(Layer_Dense(120,10))\n",
    "m.add(Activation_Softmax())\n",
    "m.set(    loss = Loss_CategoricalCrossentropy(),optimizer = Optimizer_Adam(decay = 1e-4))\n",
    "m.train( X_train, y_train,epoches= 10, batch = 120)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4f8e5d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
